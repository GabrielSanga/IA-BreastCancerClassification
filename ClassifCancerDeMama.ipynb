{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassifCancerDeMama.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DNoOSMPHXJYY"
      },
      "outputs": [],
      "source": [
        "#Importando as bibliotecas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando o dataset\n",
        "dataset = pd.read_csv(\"wdbc.data\", \n",
        "                      names=['sample_number','diagnostic','feat03','feat04','feat05','feat06','feat07','feat08','feat09','feat10','feat11','feat12','feat13','feat14','feat15','feat16',\n",
        "                             'feat17','feat18','feat19','feat20','feat21','feat22','feat23','feat24','feat25','feat26','feat27','feat28','feat29','feat30','feat31','feat32'], skiprows=1)"
      ],
      "metadata": {
        "id": "y5M8UjF2XQZs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizando o conjunto de dados\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "Znhra5YOXhK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizando as dimensões do conjunto de dados (Linhas, colunas)\n",
        "print(\"Dimensões do conjunto de dados de câncer: {}\".format(dataset.shape))"
      ],
      "metadata": {
        "id": "nqQpm1AZX_5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pontos de dados ausentes ou nulos\n",
        "dataset.isnull().sum() \n",
        "dataset.isna().sum()"
      ],
      "metadata": {
        "id": "PPF5MnmrZLGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separando as amostras dos resultados: X = Amostras / Y = Resultados\n",
        "X = dataset.iloc[:, 2:32].values\n",
        "y = dataset.iloc[:, 1].values"
      ],
      "metadata": {
        "id": "uqvWEJKPaplN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformando os dados categóricos do dataset Y em números - M -> 1 / B -> 0\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "IHx8DG67eHHa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os datasets em um conjunto de treinamento e outro conjunto de teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Treino, X_Teste, Y_Treino, Y_Teste = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "metadata": {
        "id": "-dK_RlcJkvcp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printando as dimensões dos novos dataset de treino e teste\n",
        "print(\"X Treino Dimensão : {}\".format(X_Treino.shape))\n",
        "print(\"X Teste Dimensão : {}\".format(X_Teste.shape))\n",
        "print(\"\")\n",
        "print(\"Y Treino Dimensão : {}\".format(Y_Treino.shape))\n",
        "print(\"Y Teste Dimensão : {}\".format(Y_Teste.shape))"
      ],
      "metadata": {
        "id": "K21WV7Uhl6zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizando o dimensionamento dos datasets (Transformar os dados para que caibam em uma escala. Ex: 0-100 ou 0-1)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_Treino = sc.fit_transform(X_Treino)\n",
        "X_Teste = sc.transform(X_Teste)"
      ],
      "metadata": {
        "id": "BWzqgl5Zn9IQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Iniciando a classificação dos dataset com diferentes modelos classificadores.\n",
        "Classificadores utilizados:\n",
        "\n",
        "1. Logistic Regression\n",
        "\n",
        "2. KNN\n",
        "\n",
        "3. Support Vector Machines\n",
        "\n",
        "4. Kernel SVM\n",
        "\n",
        "5. Naïve Bayes\n",
        "\n",
        "6. Decision Tree Algorithm\n",
        "\n",
        "7. Random Forest Classification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6lPir1krvhaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando Algoritmo de Regressão Logística para o Dataset de Treinamento\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_logistRegression = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno -- Basta comparar com Y_Teste e verificar a taxa de acerto \n",
        "Y_pred_logistRegression"
      ],
      "metadata": {
        "id": "7-dPuZ43p-aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando KNN Método da classe de vizinhos para usar o algoritmo do vizinho mais próximo\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_knn = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_knn"
      ],
      "metadata": {
        "id": "PvoOI6uYtG7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando o método SVC da classe svm para usar o algoritmo Support Vector Machine\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_svmLinear = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_svmLinear"
      ],
      "metadata": {
        "id": "gexB1jFHtSCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando o método SVC da classe svm para usar o algoritmo Kernel SVM\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_svmRBF = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_svmRBF"
      ],
      "metadata": {
        "id": "U_baPDb_uCTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando o método GaussianNB da classe naïve_bayes para usar o algoritmo Naïve Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_Gaussian = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_Gaussian"
      ],
      "metadata": {
        "id": "CB3KMgKPuRM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando DecisionTreeClassifier da classe de árvore para usar o algoritmo de árvore de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_DecisionTree = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_DecisionTree"
      ],
      "metadata": {
        "id": "2g4g_BKPuein"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando o método RandomForestClassifier da classe ensemble para usar o algoritmo Random Forest Classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "\n",
        "#Classificando os dados\n",
        "classifier.fit(X_Treino, Y_Treino)\n",
        "\n",
        "#Realizando testes com o dataset de teste\n",
        "Y_pred_RandomForest = classifier.predict(X_Teste)\n",
        "\n",
        "#Imprimindo o retorno\n",
        "Y_pred_RandomForest"
      ],
      "metadata": {
        "id": "4Z749MLRuyuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Verificando Acurácia atrvés da Matriz de Confusão"
      ],
      "metadata": {
        "id": "6X-24biy0sub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando confusion_matrix de sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Gerando a matriz de confusão para cada modelo classificador\n",
        "\n",
        "#Regressão Logística\n",
        "cm_logistic = confusion_matrix(Y_Teste, Y_pred_logistRegression)\n",
        "\n",
        "#KNN\n",
        "cm_knn = confusion_matrix(Y_Teste, Y_pred_knn)\n",
        "\n",
        "#SVM Linear\n",
        "cm_svmlinear = confusion_matrix(Y_Teste, Y_pred_svmLinear)\n",
        "\n",
        "#SVM RBF\n",
        "cm_svmrbf = confusion_matrix(Y_Teste, Y_pred_svmRBF)\n",
        "\n",
        "#Gaussian\n",
        "cm_gaussian = confusion_matrix(Y_Teste, Y_pred_Gaussian)\n",
        "\n",
        "#Decision Tree\n",
        "cm_decisiontree = confusion_matrix(Y_Teste, Y_pred_DecisionTree)\n",
        "\n",
        "#Random Forest\n",
        "cm_randomforest = confusion_matrix(Y_Teste, Y_pred_RandomForest)"
      ],
      "metadata": {
        "id": "jGutDYr106qv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imrpimindo a Matriz de Confusão\n",
        "print(\"Regressão Logística\")\n",
        "print(cm_logistic)\n",
        "print(\"\")\n",
        "print(\"KNN\")\n",
        "print(cm_knn)"
      ],
      "metadata": {
        "id": "ITQNuZL32QuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando accuracy score de sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Acurácia - Regressão Logística : {}\".format(accuracy_score(Y_Teste, Y_pred_logistRegression) * 100))\n",
        "print(\"Acurácia - KNN : {}\".format(accuracy_score(Y_Teste, Y_pred_knn) * 100))\n",
        "print(\"Acurácia - SVM Linear : {}\".format(accuracy_score(Y_Teste, Y_pred_svmLinear) * 100))\n",
        "print(\"Acurácia - SVM Rbf : {}\".format(accuracy_score(Y_Teste, Y_pred_svmRBF) * 100))\n",
        "print(\"Acurácia - Naive Bayes(Gaussian) : {}\".format(accuracy_score(Y_Teste, Y_pred_Gaussian) * 100))\n",
        "print(\"Acurácia - Decision Tree : {}\".format(accuracy_score(Y_Teste, Y_pred_DecisionTree) * 100))\n",
        "print(\"Acurácia - Random Forest : {}\".format(accuracy_score(Y_Teste, Y_pred_RandomForest) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzkaXsyn4axp",
        "outputId": "975f633a-fc15-4dda-da61-a894d2755933"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia - Regressão Logística : 97.1830985915493\n",
            "Acurácia - KNN : 95.77464788732394\n",
            "Acurácia - SVM Linear : 97.1830985915493\n",
            "Acurácia - SVM Rbf : 95.77464788732394\n",
            "Acurácia - Naive Bayes(Gaussian) : 92.95774647887323\n",
            "Acurácia - Decision Tree : 89.43661971830986\n",
            "Acurácia - Random Forest : 95.77464788732394\n"
          ]
        }
      ]
    }
  ]
}